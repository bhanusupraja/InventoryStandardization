# InventoryStandardization

Step 1: Create a Gemini api key from the this website
Step 2: Add the generated key to the .env file GEMINI_API_KEY = ""
Step 3: open terminal go agents path and create a virtual venv and activate it 
Step 4: run the command below
pip install -r requirements.txt
Step 5: run the command below to start the agent
python inputProcessing.py file then you could see the outputs in the data folder


# üß† InventoryStandardization

A modular AI-powered pipeline designed to **standardize, clean, and generate structured product data (SKUs, confidence scores, mappings)** from raw multi-category inventory files such as Jewelry, Textiles, Electronics, and more.

---

## üì¶ Overview

The `InventoryStandardization` project uses a series of AI and rule-based **agents** to automate inventory data transformation and SKU generation.

The goal is to:

* Process messy raw inventory data files (with 60+ columns)
* Extract and normalize only the relevant fields
* Generate standardized **SKUs**
* Compute **confidence scores**
* Route low-confidence records to **HITL (Human-in-the-Loop)** review

---

## ‚öôÔ∏è Architecture Overview

The complete pipeline includes the following agents:

| Agent                                   | Purpose                                                                              | Type              |
| --------------------------------------- | ------------------------------------------------------------------------------------ | ----------------- |
| üßπ **InputProcessingAgent**             | Cleans & extracts necessary fields from raw CSVs (e.g. Brand, Category, Description) | AI agent   |
| üß† **ConfidenceSKUAgent**               | Generates standardized SKUs & assigns confidence scores (row + column level)         | AI-assisted       |
| üîç **MappingEngineAgent**               | Classifies data into known internal schemas & identifies missing/ambiguous fields    | ML Classifier     |
| üë§ **HITL Review Agent**                | Routes low-confidence mappings (< threshold) to a review interface                   | Human-in-the-Loop |
| üìä **StatisticsAgent** *(optional)* | Aggregates logs, generates audit reports for QA                                      | AI            |

---

## ü™Ñ Features

‚úÖ Automatic SKU generation from cleaned input
‚úÖ Confidence scoring for both row-level & attribute-level data
‚úÖ Multi-domain support (Jewelry, Textiles, Electronics, etc.)
‚úÖ AI-assisted data enrichment and normalization
‚úÖ Human-in-the-loop fallback for uncertain predictions
‚úÖ Exports final standardized datasets to `.csv` and `.parquet`

---

## üß∞ Tech Stack

* **Python 3.10+**
* **Pandas** for data handling
* **FastAPI (optional)** for service orchestration
* **Google Gemini API** for AI-powered text interpretation
* **dotenv** for key management
* **scikit-learn** (planned) for classification and mapping engine

---

## üß© Setup Instructions

### 1Ô∏è‚É£ Generate a Gemini API Key

Visit [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
Copy your key and keep it secure.

---

### 2Ô∏è‚É£ Add API Key to `.env`

Create a `.env` file in the project root and paste:

```bash
GEMINI_API_KEY = "your_gemini_api_key_here"
```

---

### 3Ô∏è‚É£ Create and Activate a Virtual Environment

In the project root:

```bash
cd agents
python -m venv venv
# Activate venv
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate
```

---

### 4Ô∏è‚É£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 5Ô∏è‚É£ Run the Input Processing Agent

```bash
python inputProcessing.py
```

This step:

* Reads raw data from `data/raw/`
* Cleans and extracts essential fields
* Saves the intermediate output to `data/processed/`

---

### 6Ô∏è‚É£ Run the Confidence + SKU Agent

```bash
python confidence_sku_agent.py
```

This step:

* Loads the processed file from `data/processed/`
* Generates standardized **SKUs**
* Calculates **confidence scores**
* Flags low-confidence rows for review
* Saves final results to:

```
data/output/standardized_inventory.csv
data/output/standardized_inventory.parquet
```

---

## üìà Sample Output

| SKU               | Brand     | Category | Description        | Confidence_Score | Review_Flag |
| ----------------- | --------- | -------- | ------------------ | ---------------- | ----------- |
| JW-BR-GLD-NEC-001 | Bluestone | Jewelry  | Gold Necklace 18K  | 0.94             | No          |
| TX-FB-COT-SHR-022 | FabIndia  | Textile  | Cotton Shirt Men‚Äôs | 0.87             | Yes         |

---

## üß† Recommended Development Order

1Ô∏è‚É£ `inputProcessing.py` ‚Üí Data extraction and normalization
2Ô∏è‚É£ `confidence_sku_agent.py` ‚Üí SKU generation + confidence scoring
3Ô∏è‚É£ `mapping_engine.py` ‚Üí ML-based attribute classifier
4Ô∏è‚É£ `hitl_agent.py` ‚Üí HITL flag routing + review dashboard
5Ô∏è‚É£ `audit_reporting.py` *(optional)* ‚Üí Logging and QA reports

---

## üßæ Example Folder Structure

InventoryStandardization/
‚îÇ
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ inputProcessing.py
‚îÇ   ‚îú‚îÄ‚îÄ confidence_sku_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ mapping_engine.py
‚îÇ   ‚îú‚îÄ‚îÄ hitl_agent.py
‚îÇ   ‚îî‚îÄ‚îÄ audit_reporting.py
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ output/
‚îÇ
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
